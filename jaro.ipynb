{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from py_stringmatching import JaroWinkler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = pd.read_csv(\"original data/trafficlist_forcountry.csv\")\n",
    "forest = pd.read_csv(\"original data/forest-cover-v1.csv\")\n",
    "air_city = pd.read_csv(\"original data/aap_air_quality_database_2018_v14.csv\", skiprows=2)\n",
    "air_country = pd.read_csv(\"original data/【12】GlobalPM25-1998-2022.csv\")\n",
    "weather = pd.read_csv(\"original data/GlobalWeatherRepository.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country - Jaro-Winkler\n",
    "jw = JaroWinkler()\n",
    "threshold = 0.90 # Set the matching threshold (adjustable)\n",
    "matches1 = [] # result\n",
    "\n",
    "traffic['Location'] = traffic['Location'].str.lower().str.strip()\n",
    "forest['Country Name'] = forest['Country Name'].str.lower().str.strip()\n",
    "air_city['Country'] = air_city['Country'].str.lower().str.strip()\n",
    "air_country['Region'] = air_country['Region'].str.lower().str.strip()\n",
    "weather['country'] = weather['country'].str.lower().str.strip()\n",
    "\n",
    "# 2. Extract prefix column\n",
    "prefix_length = 3\n",
    "\n",
    "traffic['country_prefix'] = traffic['Location'].str[:prefix_length]\n",
    "forest['country_prefix'] = forest['Country Name'].str[:prefix_length]\n",
    "air_city['country_prefix'] = air_city['Country'].str[:prefix_length]\n",
    "air_country['country_prefix'] = air_country['Region'].str[:prefix_length]\n",
    "weather['country_prefix'] = weather['country'].str[:prefix_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common country prefixes are: {'nep', 'hun', 'sie', 'new', 'nor', 'geo', 'sud', 'mex', 'sin', 'isr', 'egy', 'ton', 'uru', 'tur', 'lux', 'lat', 'mor', 'ecu', 'far', 'bru', 'pap', 'uni', 'jap', 'el ', 'pol', 'jor', 'zam', 'mal', 'sey', 'tun', 'nam', 'bur', 'pal', 'bot', 'mad', 'gui', 'tha', 'ben', 'slo', 'dji', 'eri', 'est', 'uzb', 'mol', 'nig', 'fin', 'tan', 'dom', 'cub', 'gib', 'swe', 'alg', 'lie', 'nau', 'alb', 'phi', 'fra', 'ind', 'moz', 'cen', 'ire', 'taj', 'bul', 'den', 'isl', 'gua', 'kaz', 'tri', 'oma', 'bar', 'ice', 'cha', 'som', 'net', 'cro', 'bel', 'sen', 'cze', 'spa', 'aze', 'lib', 'ita', 'bos', 'kyr', 'mon', 'pak', 'ira', 'fij', 'kir', 'arm', 'ven', 'rom', 'afg', 'ban', 'mic', 'aus', 'sol', 'com', 'cam', 'leb', 'can', 'sau', 'rwa', 'eth', 'gam', 'lao', 'bhu', 'mya', 'bol', 'kuw', 'sam', 'cyp', 'gre', 'san', 'chi', 'sou', 'lit', 'zim', 'por', 'qat', 'ukr', 'bah', 'sri', 'ken', 'arg', 'mac', 'ger', 'gha', 'syr', 'swi', 'rus', 'guy', 'and', 'ant', 'uga', 'sur', 'col', 'vie', 'tog', 'ser', 'pan', 'jam', 'cos', 'bra', 'per', 'hon'}\n",
      "    Prefix     Country_A     Country_B  Similarity\n",
      "0      nep         nepal         nepal         1.0\n",
      "1      hun       hungary       hungary         1.0\n",
      "2      sie  sierra leone  sierra leone         1.0\n",
      "3      new   new zealand   new zealand         1.0\n",
      "4      nor        norway        norway         1.0\n",
      "..     ...           ...           ...         ...\n",
      "157    jam       jamaica       jamaica         1.0\n",
      "158    cos    costa rica    costa rica         1.0\n",
      "159    bra        brazil        brazil         1.0\n",
      "160    per          peru          peru         1.0\n",
      "161    hon      honduras      honduras         1.0\n",
      "\n",
      "[162 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# traffic-forest\n",
    "\n",
    "# Find common prefixes (blocking)\n",
    "common_prefixes = set(traffic['country_prefix']).intersection(set(forest['country_prefix']))\n",
    "print(f\"Common country prefixes are: {common_prefixes}\")\n",
    "\n",
    "# For each common prefix, compare countries\n",
    "for prefix in common_prefixes:\n",
    "    subset_a = traffic[traffic['country_prefix'] == prefix]\n",
    "    subset_b = forest[forest['country_prefix'] == prefix]\n",
    "    \n",
    "    for country_a in subset_a['Location'].unique():\n",
    "        for country_b in subset_b['Country Name'].unique():\n",
    "            score = jw.get_sim_score(str(country_a), str(country_b))\n",
    "            if score >= threshold:\n",
    "                matches1.append({\n",
    "                    \"Prefix\": prefix,\n",
    "                    \"Country_A\": country_a,\n",
    "                    \"Country_B\": country_b,\n",
    "                    \"Similarity\": round(score, 4)\n",
    "                })\n",
    "\n",
    "# Convert to DataFrame and display results\n",
    "result_df = pd.DataFrame(matches1)\n",
    "print(result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common country prefixes are: {'nep', 'hun', 'new', 'nor', 'geo', 'mex', 'sin', 'isr', 'uru', 'tur', 'lux', 'lat', 'mor', 'ecu', 'uni', 'jap', 'el ', 'pol', 'jor', 'mal', 'mad', 'tha', 'slo', 'est', 'fin', 'cub', 'swe', 'alb', 'phi', 'fra', 'ind', 'ire', 'bul', 'den', 'gua', 'ice', 'net', 'cro', 'bel', 'sen', 'cze', 'spa', 'lib', 'ita', 'bos', 'mon', 'pak', 'fij', 'ira', 'rom', 'ban', 'aus', 'cam', 'leb', 'can', 'sau', 'kuw', 'cyp', 'gre', 'chi', 'sou', 'lit', 'por', 'ukr', 'bah', 'ken', 'ger', 'gha', 'swi', 'rus', 'and', 'uga', 'col', 'vie', 'ser', 'pan', 'cos', 'bra', 'per'}\n",
      "    Prefix     Country_A     Country_B  Similarity\n",
      "0      nep         nepal         nepal         1.0\n",
      "1      hun       hungary       hungary         1.0\n",
      "2      sie  sierra leone  sierra leone         1.0\n",
      "3      new   new zealand   new zealand         1.0\n",
      "4      nor        norway        norway         1.0\n",
      "..     ...           ...           ...         ...\n",
      "241    ser        serbia        serbia         1.0\n",
      "242    pan        panama        panama         1.0\n",
      "243    cos    costa rica    costa rica         1.0\n",
      "244    bra        brazil        brazil         1.0\n",
      "245    per          peru          peru         1.0\n",
      "\n",
      "[246 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# traffic-air-city\n",
    "# Find common prefixes (blocking)\n",
    "common_prefixes = set(traffic['country_prefix']).intersection(set(air_city['country_prefix']))\n",
    "print(f\"Common country prefixes are: {common_prefixes}\")\n",
    "\n",
    "# For each common prefix, compare countries\n",
    "for prefix in common_prefixes:\n",
    "    subset_a = traffic[traffic['country_prefix'] == prefix]\n",
    "    subset_b = air_city[air_city['country_prefix'] == prefix]\n",
    "    \n",
    "    for country_a in subset_a['Location'].unique():\n",
    "        for country_b in subset_b['Country'].unique():\n",
    "            score = jw.get_sim_score(str(country_a), str(country_b))\n",
    "            if score >= threshold:\n",
    "                matches1.append({\n",
    "                    \"Prefix\": prefix,\n",
    "                    \"Country_A\": country_a,\n",
    "                    \"Country_B\": country_b,\n",
    "                    \"Similarity\": round(score, 4)\n",
    "                })\n",
    "\n",
    "#  Convert to DataFrame and display results\n",
    "result_df = pd.DataFrame(matches1)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common country prefixes are: {'nep', 'hun', 'sie', 'new', 'nor', 'geo', 'sud', 'mex', 'sin', 'isr', 'egy', 'ton', 'uru', 'tur', 'lux', 'lat', 'mor', 'ecu', 'far', 'cap', 'bru', 'pap', 'uni', 'jap', 'el ', 'pol', 'jor', 'zam', 'mal', 'sey', 'tun', 'nam', 'bur', 'pal', 'bot', 'mad', 'gui', 'tha', 'ben', 'slo', 'dji', 'eri', 'est', 'uzb', 'mol', 'nig', 'fin', 'tan', 'dom', 'cub', 'gib', 'swe', 'alg', 'lie', 'nau', 'alb', 'phi', 'fra', 'ind', 'moz', 'cen', 'ire', 'taj', 'bul', 'den', 'isl', 'gua', 'kaz', 'tri', 'oma', 'bar', 'gue', 'ice', 'cha', 'som', 'net', 'cro', 'bel', 'sen', 'kos', 'cze', 'spa', 'aze', 'lib', 'ita', 'bos', 'kyr', 'tai', 'mon', 'pak', 'ira', 'fij', 'kir', 'arm', 'ven', 'rom', 'afg', 'ban', 'mic', 'aus', 'sol', 'com', 'cam', 'leb', 'can', 'sau', 'rwa', 'eth', 'sai', 'gam', 'lao', 'bhu', 'mya', 'bol', 'kuw', 'jer', 'sam', 'cyp', 'gre', 'san', 'chi', 'sou', 'lit', 'zim', 'por', 'qat', 'ukr', 'bah', 'sri', 'ken', 'arg', 'mac', 'ger', 'gha', 'syr', 'swi', 'rus', 'guy', 'and', 'ant', 'uga', 'sur', 'col', 'são', 'vie', 'ser', 'tog', 'pan', 'jam', 'cos', 'bra', 'per', 'hon'}\n",
      "    Prefix          Country_A     Country_B  Similarity\n",
      "0      nep              nepal         nepal      1.0000\n",
      "1      hun            hungary       hungary      1.0000\n",
      "2      sie       sierra leone  sierra leone      1.0000\n",
      "3      new        new zealand   new zealand      1.0000\n",
      "4      nor             norway        norway      1.0000\n",
      "..     ...                ...           ...         ...\n",
      "423    cos         costa rica    costa rica      1.0000\n",
      "424    bra             brazil        brazil      1.0000\n",
      "425    per               peru          peru      1.0000\n",
      "426    hon           honduras      honduras      1.0000\n",
      "427    hon  hong kong (china)     hong kong      0.9059\n",
      "\n",
      "[428 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# traffic-air-country\n",
    "common_prefixes = set(traffic['country_prefix']).intersection(set(air_country['country_prefix']))\n",
    "print(f\"Common country prefixes are: {common_prefixes}\")\n",
    "\n",
    "# For each common prefix, compare countries\n",
    "for prefix in common_prefixes:\n",
    "    subset_a = traffic[traffic['country_prefix'] == prefix]\n",
    "    subset_b = air_country[air_country['country_prefix'] == prefix]\n",
    "    \n",
    "    for country_a in subset_a['Location'].unique():\n",
    "        for country_b in subset_b['Region'].unique():\n",
    "            score = jw.get_sim_score(str(country_a), str(country_b))\n",
    "            if score >= threshold:\n",
    "                matches1.append({\n",
    "                    \"Prefix\": prefix,\n",
    "                    \"Country_A\": country_a,\n",
    "                    \"Country_B\": country_b,\n",
    "                    \"Similarity\": round(score, 4)\n",
    "                })\n",
    "\n",
    "#  Convert to DataFrame and display results\n",
    "result_df = pd.DataFrame(matches1)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common country prefixes are: {'nep', 'hun', 'sie', 'new', 'nor', 'geo', 'sud', 'mex', 'sin', 'isr', 'egy', 'ton', 'uru', 'tur', 'lux', 'lat', 'mor', 'ecu', 'cap', 'bru', 'pap', 'uni', 'jap', 'el ', 'pol', 'jor', 'zam', 'mal', 'sey', 'tun', 'nam', 'bur', 'pal', 'bot', 'mad', 'gui', 'tha', 'ben', 'slo', 'dji', 'eri', 'est', 'uzb', 'nig', 'fin', 'tan', 'dom', 'cub', 'swe', 'alg', 'lie', 'alb', 'phi', 'fra', 'ind', 'moz', 'cen', 'ire', 'taj', 'bul', 'den', 'gua', 'kaz', 'tri', 'oma', 'bar', 'ice', 'cha', 'som', 'net', 'cro', 'bel', 'sen', 'cze', 'spa', 'aze', 'lib', 'ita', 'bos', 'kyr', 'mon', 'pak', 'ira', 'fij', 'kir', 'arm', 'ven', 'rom', 'afg', 'ban', 'mic', 'aus', 'sol', 'com', 'cam', 'leb', 'can', 'sau', 'rwa', 'eth', 'sai', 'gam', 'bhu', 'mya', 'bol', 'kuw', 'sam', 'cyp', 'gre', 'san', 'chi', 'sou', 'lit', 'zim', 'por', 'qat', 'ukr', 'bah', 'sri', 'ken', 'arg', 'mac', 'ger', 'gha', 'syr', 'swi', 'rus', 'guy', 'and', 'ant', 'uga', 'sur', 'vie', 'ser', 'pan', 'jam', 'cos', 'bra', 'per', 'hon'}\n",
      "    Prefix     Country_A     Country_B  Similarity\n",
      "0      nep         nepal         nepal         1.0\n",
      "1      hun       hungary       hungary         1.0\n",
      "2      sie  sierra leone  sierra leone         1.0\n",
      "3      new   new zealand   new zealand         1.0\n",
      "4      nor        norway        norway         1.0\n",
      "..     ...           ...           ...         ...\n",
      "587    jam       jamaica       jamaica         1.0\n",
      "588    cos    costa rica    costa rica         1.0\n",
      "589    bra        brazil        brazil         1.0\n",
      "590    per          peru          peru         1.0\n",
      "591    hon      honduras      honduras         1.0\n",
      "\n",
      "[592 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# traffic-weather\n",
    "common_prefixes = set(traffic['country_prefix']).intersection(set(weather['country_prefix']))\n",
    "print(f\"Common country prefixes are: {common_prefixes}\")\n",
    "\n",
    "# For each common prefix, compare countries\n",
    "for prefix in common_prefixes:\n",
    "    subset_a = traffic[traffic['country_prefix'] == prefix]\n",
    "    subset_b = weather[weather['country_prefix'] == prefix]\n",
    "    \n",
    "    for country_a in subset_a['Location'].unique():\n",
    "        for country_b in subset_b['country'].unique():\n",
    "            score = jw.get_sim_score(str(country_a), str(country_b))\n",
    "            if score >= threshold:\n",
    "                matches1.append({\n",
    "                    \"Prefix\": prefix,\n",
    "                    \"Country_A\": country_a,\n",
    "                    \"Country_B\": country_b,\n",
    "                    \"Similarity\": round(score, 4)\n",
    "                })\n",
    "\n",
    "#  Convert to DataFrame and display results\n",
    "result_df = pd.DataFrame(matches1)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common country prefixes are: {'nep', 'hun', 'sie', 'new', 'nor', 'geo', 'hai', 'sud', 'egy', 'mex', 'isr', 'sin', 'ton', 'uru', 'tur', 'lux', 'lat', 'mor', 'mau', 'ecu', 'bru', 'pap', 'tuv', 'el ', 'jap', 'uni', 'pol', 'jor', 'zam', 'mal', 'sey', 'nam', 'bur', 'tun', 'pal', 'bot', 'mad', 'gui', 'ben', 'equ', 'tha', 'slo', 'dji', 'eri', 'est', 'uzb', 'nig', 'fin', 'tan', 'dom', 'cub', 'swe', 'alg', 'yem', 'lie', 'alb', 'phi', 'tim', 'fra', 'ind', 'moz', 'cen', 'ire', 'taj', 'bul', 'den', 'ang', 'van', 'gua', 'kaz', 'con', 'par', 'gab', 'tri', 'oma', 'bar', 'ice', 'cha', 'som', 'net', 'cro', 'bel', 'sen', 'cze', 'aze', 'spa', 'lib', 'ita', 'nic', 'bos', 'kyr', 'mon', 'pak', 'fij', 'ira', 'kir', 'arm', 'ven', 'rom', 'afg', 'ban', 'mic', 'aus', 'sol', 'com', 'cam', 'leb', 'can', 'les', 'sau', 'rwa', 'eth', 'gam', 'bhu', 'mya', 'bol', 'kuw', 'sam', 'cyp', 'gre', 'san', 'chi', 'sou', 'lit', 'zim', 'por', 'qat', 'ukr', 'bah', 'sri', 'ken', 'arg', 'mar', 'ger', 'gha', 'mac', 'syr', 'swi', 'rus', 'guy', 'and', 'ant', 'uga', 'sur', 'vie', 'ser', 'pan', 'jam', 'cos', 'bra', 'per', 'hon'}\n",
      "    Prefix     Country_A     Country_B  Similarity\n",
      "0      nep         nepal         nepal         1.0\n",
      "1      hun       hungary       hungary         1.0\n",
      "2      sie  sierra leone  sierra leone         1.0\n",
      "3      new   new zealand   new zealand         1.0\n",
      "4      nor        norway        norway         1.0\n",
      "..     ...           ...           ...         ...\n",
      "758    jam       jamaica       jamaica         1.0\n",
      "759    cos    costa rica    costa rica         1.0\n",
      "760    bra        brazil        brazil         1.0\n",
      "761    per          peru          peru         1.0\n",
      "762    hon      honduras      honduras         1.0\n",
      "\n",
      "[763 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# air-country-weather\n",
    "common_prefixes = set(forest['country_prefix']).intersection(set(weather['country_prefix']))\n",
    "print(f\"Common country prefixes are: {common_prefixes}\")\n",
    "\n",
    "# For each common prefix, compare countries\n",
    "for prefix in common_prefixes:\n",
    "    subset_a = forest[forest['country_prefix'] == prefix]\n",
    "    subset_b = weather[weather['country_prefix'] == prefix]\n",
    "    \n",
    "    for country_a in subset_a['Country Name'].unique():\n",
    "        for country_b in subset_b['country'].unique():\n",
    "            score = jw.get_sim_score(str(country_a), str(country_b))\n",
    "            if score >= threshold:\n",
    "                matches1.append({\n",
    "                    \"Prefix\": prefix,\n",
    "                    \"Country_A\": country_a,\n",
    "                    \"Country_B\": country_b,\n",
    "                    \"Similarity\": round(score, 4)\n",
    "                })\n",
    "\n",
    "#  Convert to DataFrame and display results\n",
    "result_df = pd.DataFrame(matches1)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common country prefixes are: {'nep', 'hun', 'new', 'nor', 'geo', 'mex', 'sin', 'isr', 'uru', 'tur', 'lux', 'lat', 'mor', 'ecu', 'uni', 'jap', 'el ', 'pol', 'jor', 'mal', 'mad', 'tha', 'slo', 'est', 'fin', 'cub', 'swe', 'alb', 'phi', 'fra', 'ind', 'ire', 'bul', 'den', 'gua', 'par', 'ice', 'net', 'cro', 'bel', 'sen', 'cze', 'spa', 'lib', 'ita', 'bos', 'mon', 'pak', 'fij', 'ira', 'rom', 'ban', 'aus', 'cam', 'leb', 'can', 'sau', 'kuw', 'cyp', 'gre', 'chi', 'sou', 'lit', 'por', 'ukr', 'bah', 'ken', 'ger', 'gha', 'swi', 'rus', 'and', 'uga', 'col', 'vie', 'ser', 'pan', 'cos', 'bra', 'per'}\n",
      "    Prefix     Country_A     Country_B  Similarity\n",
      "0      nep         nepal         nepal         1.0\n",
      "1      hun       hungary       hungary         1.0\n",
      "2      sie  sierra leone  sierra leone         1.0\n",
      "3      new   new zealand   new zealand         1.0\n",
      "4      nor        norway        norway         1.0\n",
      "..     ...           ...           ...         ...\n",
      "844    ser        serbia        serbia         1.0\n",
      "845    pan        panama        panama         1.0\n",
      "846    cos    costa rica    costa rica         1.0\n",
      "847    bra        brazil        brazil         1.0\n",
      "848    per          peru          peru         1.0\n",
      "\n",
      "[849 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# forest-air-city\n",
    "common_prefixes = set(forest['country_prefix']).intersection(set(air_city['country_prefix']))\n",
    "print(f\"Common country prefixes are: {common_prefixes}\")\n",
    "\n",
    "# For each common prefix, compare countries\n",
    "for prefix in common_prefixes:\n",
    "    subset_a = forest[forest['country_prefix'] == prefix]\n",
    "    subset_b = air_city[air_city['country_prefix'] == prefix]\n",
    "    \n",
    "    for country_a in subset_a['Country Name'].unique():\n",
    "        for country_b in subset_b['Country'].unique():\n",
    "            score = jw.get_sim_score(str(country_a), str(country_b))\n",
    "            if score >= threshold:\n",
    "                matches1.append({\n",
    "                    \"Prefix\": prefix,\n",
    "                    \"Country_A\": country_a,\n",
    "                    \"Country_B\": country_b,\n",
    "                    \"Similarity\": round(score, 4)\n",
    "                })\n",
    "\n",
    "#  Convert to DataFrame and display results\n",
    "result_df = pd.DataFrame(matches1)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common country prefixes are: {'nep', 'hun', 'sie', 'new', 'nor', 'geo', 'hai', 'sud', 'egy', 'mex', 'isr', 'sin', 'ton', 'vir', 'uru', 'tur', 'lux', 'lat', 'mor', 'mau', 'ecu', 'far', 'bru', 'pap', 'tuv', 'uni', 'jap', 'el ', 'pol', 'jor', 'zam', 'mal', 'sey', 'nam', 'bur', 'tun', 'pal', 'bot', 'mad', 'gui', 'ben', 'equ', 'slo', 'tha', 'dji', 'fre', 'eri', 'est', 'uzb', 'mol', 'nig', 'fin', 'tan', 'dom', 'cub', 'gib', 'pue', 'alg', 'swe', 'yem', 'lie', 'nau', 'alb', 'phi', 'tim', 'fra', 'ind', 'moz', 'cen', 'ire', 'taj', 'wes', 'aru', 'bul', 'den', 'ang', 'van', 'cay', 'isl', 'gua', 'kaz', 'par', 'ame', 'gab', 'ber', 'oma', 'bar', 'tri', 'ice', 'cha', 'som', 'net', 'cro', 'bel', 'sen', 'cze', 'aze', 'spa', 'lib', 'ita', 'nic', 'bos', 'kyr', 'cur', 'mon', 'pak', 'fij', 'ira', 'kir', 'arm', 'ven', 'rom', 'afg', 'ban', 'mic', 'aus', 'sol', 'com', 'cam', 'leb', 'can', 'les', 'sau', 'rwa', 'eth', 'gam', 'lao', 'bhu', 'mya', 'bol', 'bri', 'kuw', 'sam', 'cyp', 'gre', 'san', 'chi', 'sou', 'lit', 'zim', 'por', 'qat', 'ukr', 'bah', 'sri', 'ken', 'arg', 'mac', 'ger', 'gha', 'mar', 'syr', 'swi', 'rus', 'guy', 'and', 'ant', 'uga', 'col', 'sur', 'vie', 'tog', 'ser', 'pan', 'jam', 'cos', 'bra', 'per', 'hon'}\n",
      "     Prefix     Country_A     Country_B  Similarity\n",
      "0       nep         nepal         nepal         1.0\n",
      "1       hun       hungary       hungary         1.0\n",
      "2       sie  sierra leone  sierra leone         1.0\n",
      "3       new   new zealand   new zealand         1.0\n",
      "4       nor        norway        norway         1.0\n",
      "...     ...           ...           ...         ...\n",
      "1037    jam       jamaica       jamaica         1.0\n",
      "1038    cos    costa rica    costa rica         1.0\n",
      "1039    bra        brazil        brazil         1.0\n",
      "1040    per          peru          peru         1.0\n",
      "1041    hon      honduras      honduras         1.0\n",
      "\n",
      "[1042 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# forest-air-country\n",
    "common_prefixes = set(forest['country_prefix']).intersection(set(air_country['country_prefix']))\n",
    "print(f\"Common country prefixes are: {common_prefixes}\")\n",
    "\n",
    "# For each common prefix, compare countries\n",
    "for prefix in common_prefixes:\n",
    "    subset_a = forest[forest['country_prefix'] == prefix]\n",
    "    subset_b = air_country[air_country['country_prefix'] == prefix]\n",
    "    \n",
    "    for country_a in subset_a['Country Name'].unique():\n",
    "        for country_b in subset_b['Region'].unique():\n",
    "            score = jw.get_sim_score(str(country_a), str(country_b))\n",
    "            if score >= threshold:\n",
    "                matches1.append({\n",
    "                    \"Prefix\": prefix,\n",
    "                    \"Country_A\": country_a,\n",
    "                    \"Country_B\": country_b,\n",
    "                    \"Similarity\": round(score, 4)\n",
    "                })\n",
    "\n",
    "#  Convert to DataFrame and display results\n",
    "result_df = pd.DataFrame(matches1)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common country prefixes are: {'nep', 'hun', 'new', 'nor', 'geo', 'mex', 'sin', 'isr', 'uru', 'tur', 'lux', 'lat', 'mor', 'ecu', 'uni', 'jap', 'el ', 'pol', 'jor', 'mal', 'mad', 'tha', 'slo', 'est', 'fin', 'cub', 'swe', 'alb', 'phi', 'fra', 'ind', 'ire', 'bul', 'den', 'rep', 'gua', 'par', 'ice', 'net', 'cro', 'bel', 'sen', 'cze', 'spa', 'lib', 'ita', 'bos', 'mon', 'pak', 'fij', 'ira', 'rom', 'ban', 'aus', 'cam', 'leb', 'can', 'sau', 'kuw', 'cyp', 'gre', 'chi', 'sou', 'lit', 'por', 'ukr', 'bah', 'ken', 'ger', 'gha', 'swi', 'rus', 'and', 'uga', 'col', 'vie', 'ser', 'pan', 'cos', 'bra', 'per'}\n",
      "     Prefix     Country_A     Country_B  Similarity\n",
      "0       nep         nepal         nepal         1.0\n",
      "1       hun       hungary       hungary         1.0\n",
      "2       sie  sierra leone  sierra leone         1.0\n",
      "3       new   new zealand   new zealand         1.0\n",
      "4       nor        norway        norway         1.0\n",
      "...     ...           ...           ...         ...\n",
      "1123    ser        serbia        serbia         1.0\n",
      "1124    pan        panama        panama         1.0\n",
      "1125    cos    costa rica    costa rica         1.0\n",
      "1126    bra        brazil        brazil         1.0\n",
      "1127    per          peru          peru         1.0\n",
      "\n",
      "[1128 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# air-country-air-city\n",
    "common_prefixes = set(air_country['country_prefix']).intersection(set(air_city['country_prefix']))\n",
    "print(f\"Common country prefixes are: {common_prefixes}\")\n",
    "\n",
    "# For each common prefix, compare countries\n",
    "for prefix in common_prefixes:\n",
    "    subset_a = air_country[air_country['country_prefix'] == prefix]\n",
    "    subset_b = air_city[air_city['country_prefix'] == prefix]\n",
    "    \n",
    "    for country_a in subset_a['Region'].unique():\n",
    "        for country_b in subset_b['Country'].unique():\n",
    "            score = jw.get_sim_score(str(country_a), str(country_b))\n",
    "            if score >= threshold:\n",
    "                matches1.append({\n",
    "                    \"Prefix\": prefix,\n",
    "                    \"Country_A\": country_a,\n",
    "                    \"Country_B\": country_b,\n",
    "                    \"Similarity\": round(score, 4)\n",
    "                })\n",
    "\n",
    "#  Convert to DataFrame and display results\n",
    "result_df = pd.DataFrame(matches1)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City - Jaro-Winkler\n",
    "jw = JaroWinkler()\n",
    "threshold = 0.90\n",
    "matches2 = []\n",
    "\n",
    "cities_air_city = air_city['City/Town'].dropna().unique()\n",
    "cities_air_weather = weather['location_name'].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China's common cities are: set()\n",
      "            City_a             City_B  Similarity\n",
      "0           Tirana             Tirana      1.0000\n",
      "1         Canberra           Canberra      1.0000\n",
      "2         Brussels           Brussels      1.0000\n",
      "3            Dhaka              Dhaka      1.0000\n",
      "4            Sofia              Sofia      1.0000\n",
      "..             ...                ...         ...\n",
      "102  San Francisco      San Francisco      1.0000\n",
      "103     San Rafael         San Rafael      1.0000\n",
      "104    Victorville           Victoria      0.9023\n",
      "105     Washington    Washington Park      0.9333\n",
      "106     Washington  Washington Harbor      0.9176\n",
      "\n",
      "[107 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Blocking strategy\n",
    "#Hash Strategy - city to city\n",
    "#Categorize the cities by their country, and pick an example [ex: China] for comparison\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "cities_air_city = air_city['City/Town'].dropna().unique()\n",
    "cities_air_weather = weather['location_name'].dropna().unique()\n",
    "\n",
    "# 1. Preprocessing: remove empty values, unify format (lowercase & remove spaces)\n",
    "air_city['City/Town'] = air_city['City/Town'].str.lower().str.strip()\n",
    "air_city['Country'] = air_city['Country'].str.lower().str.strip()\n",
    "weather['location_name'] = weather['location_name'].str.lower().str.strip()\n",
    "weather['country'] = weather['country'].str.lower().str.strip()\n",
    "\n",
    "# 2. Filter records whose country is China\n",
    "cities_air_city_China = air_city[air_city['Country'] == 'China']\n",
    "cities_air_weather_China = weather[weather['country'] == 'China']\n",
    "\n",
    "# 3. Finding common cities (Blocking)\n",
    "common_cities = set(cities_air_city_China['City/Town']).intersection(\n",
    "    set(cities_air_weather_China['location_name'])\n",
    ")\n",
    "\n",
    "print(f\"China's common cities are: {common_cities}\")\n",
    "\n",
    "# 4. Make matching combinations in common cities\n",
    "# air-city-weather\n",
    "for city_a in cities_air_city:\n",
    "    for city_b in cities_air_weather:\n",
    "        score = jw.get_sim_score(str(city_a), str(city_b))\n",
    "        if score >= threshold:\n",
    "            matches2.append({\n",
    "                \"City_a\": city_a,\n",
    "                \"City_B\": city_b,\n",
    "                \"Similarity\": round(score, 4)\n",
    "            })\n",
    "\n",
    "# reslt\n",
    "result_df = pd.DataFrame(matches2)\n",
    "print(result_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
